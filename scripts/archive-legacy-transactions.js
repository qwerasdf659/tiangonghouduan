#!/usr/bin/env node

/**
 * @file æ—§ææ–™å’Œé’»çŸ³æµæ°´å½’æ¡£è„šæœ¬ï¼ˆPhase 4ï¼‰
 * @description å°†æ—§çš„ææ–™æµæ°´å’Œé’»çŸ³æµæ°´å½’æ¡£åˆ°å†å²è¡¨æˆ–å¯¼å‡ºåˆ°å¤‡ä»½æ–‡ä»¶
 *
 * ä½¿ç”¨æ–¹æ³•ï¼š
 * 1. ä»…ç»Ÿè®¡ï¼ˆä¸æ‰§è¡Œå½’æ¡£ï¼‰ï¼šnode scripts/archive-legacy-transactions.js --dry-run
 * 2. å½’æ¡£åˆ°å†å²è¡¨ï¼šnode scripts/archive-legacy-transactions.js --mode=archive
 * 3. å¯¼å‡ºåˆ°æ–‡ä»¶ï¼šnode scripts/archive-legacy-transactions.js --mode=export --output=./backups/legacy_transactions_2025.json
 *
 * å‚æ•°è¯´æ˜ï¼š
 * --dry-run: ä»…ç»Ÿè®¡æ•°æ®ï¼Œä¸æ‰§è¡Œå®é™…å½’æ¡£
 * --mode: å½’æ¡£æ¨¡å¼ï¼Œarchiveï¼ˆå½’æ¡£åˆ°å†å²è¡¨ï¼‰æˆ– exportï¼ˆå¯¼å‡ºåˆ°æ–‡ä»¶ï¼‰
 * --output: å¯¼å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆmode=exportæ—¶å¿…å¡«ï¼‰
 * --before-date: å½’æ¡£æŒ‡å®šæ—¥æœŸä¹‹å‰çš„æ•°æ®ï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰ï¼Œé»˜è®¤ä¸é™åˆ¶
 * --batch-size: æ‰¹é‡å¤„ç†æ•°é‡ï¼Œé»˜è®¤ 1000
 */

const path = require('path')
const fs = require('fs').promises
require('dotenv').config()

const { sequelize } = require('../models')

// ç®€åŒ–æ—¥å¿—è¾“å‡ºï¼Œä¸ä¾èµ–Loggeræ¨¡å—
const logger = {
  info: (msg, data) => console.log(`[INFO] ${msg}`, data || ''),
  error: (msg, data) => console.error(`[ERROR] ${msg}`, data || '')
}

// ç®€åŒ–æ—¶é—´å¤„ç†ï¼Œä¸ä¾èµ–BeijingTimeHelper
const formatTime = date => {
  return new Date(date).toLocaleString('zh-CN', { timeZone: 'Asia/Shanghai' })
}

// è§£æå‘½ä»¤è¡Œå‚æ•°
function parseArgs() {
  const args = process.argv.slice(2)
  const options = {
    dryRun: false,
    mode: 'archive', // archive æˆ– export
    output: null,
    beforeDate: null,
    batchSize: 1000
  }

  args.forEach(arg => {
    if (arg === '--dry-run') {
      options.dryRun = true
    } else if (arg.startsWith('--mode=')) {
      options.mode = arg.split('=')[1]
    } else if (arg.startsWith('--output=')) {
      options.output = arg.split('=')[1]
    } else if (arg.startsWith('--before-date=')) {
      options.beforeDate = arg.split('=')[1]
    } else if (arg.startsWith('--batch-size=')) {
      options.batchSize = parseInt(arg.split('=')[1])
    }
  })

  return options
}

// éªŒè¯å‚æ•°
function validateOptions(options) {
  if (!['archive', 'export'].includes(options.mode)) {
    throw new Error('--mode å¿…é¡»æ˜¯ archive æˆ– export')
  }

  if (options.mode === 'export' && !options.output) {
    throw new Error('--mode=export æ—¶å¿…é¡»æŒ‡å®š --output å‚æ•°')
  }

  if (options.beforeDate && !/^\d{4}-\d{2}-\d{2}$/.test(options.beforeDate)) {
    throw new Error('--before-date æ ¼å¼å¿…é¡»æ˜¯ YYYY-MM-DD')
  }

  if (options.batchSize < 1 || options.batchSize > 10000) {
    throw new Error('--batch-size å¿…é¡»åœ¨ 1-10000 ä¹‹é—´')
  }
}

// ç»Ÿè®¡æ—§æµæ°´æ•°æ®
async function statisticsLegacyTransactions(beforeDate) {
  const stats = {
    material_transactions: 0,
    diamond_transactions: 0,
    earliest_material: null,
    latest_material: null,
    earliest_diamond: null,
    latest_diamond: null
  }

  // æ„å»ºæŸ¥è¯¢æ¡ä»¶
  const whereClause = beforeDate ? { created_at: { [sequelize.Sequelize.Op.lt]: beforeDate } } : {}

  // ç»Ÿè®¡ææ–™æµæ°´
  const [materialStats] = await sequelize.query(
    `
    SELECT 
      COUNT(*) as total,
      MIN(created_at) as earliest,
      MAX(created_at) as latest
    FROM material_transactions
    ${beforeDate ? 'WHERE created_at < :beforeDate' : ''}
  `,
    {
      replacements: { beforeDate },
      type: sequelize.QueryTypes.SELECT
    }
  )

  stats.material_transactions = parseInt(materialStats.total)
  stats.earliest_material = materialStats.earliest
  stats.latest_material = materialStats.latest

  // ç»Ÿè®¡é’»çŸ³æµæ°´
  const [diamondStats] = await sequelize.query(
    `
    SELECT 
      COUNT(*) as total,
      MIN(created_at) as earliest,
      MAX(created_at) as latest
    FROM diamond_transactions
    ${beforeDate ? 'WHERE created_at < :beforeDate' : ''}
  `,
    {
      replacements: { beforeDate },
      type: sequelize.QueryTypes.SELECT
    }
  )

  stats.diamond_transactions = parseInt(diamondStats.total)
  stats.earliest_diamond = diamondStats.earliest
  stats.latest_diamond = diamondStats.latest

  return stats
}

// å½’æ¡£åˆ°å†å²è¡¨
async function archiveToHistoryTables(beforeDate, batchSize) {
  logger.info('å¼€å§‹å½’æ¡£åˆ°å†å²è¡¨...', { beforeDate, batchSize })

  const transaction = await sequelize.transaction()

  try {
    // 1. åˆ›å»ºå†å²è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    await sequelize.query(
      `
      CREATE TABLE IF NOT EXISTS material_transactions_history LIKE material_transactions
    `,
      { transaction }
    )

    await sequelize.query(
      `
      CREATE TABLE IF NOT EXISTS diamond_transactions_history LIKE diamond_transactions
    `,
      { transaction }
    )

    logger.info('å†å²è¡¨å·²å‡†å¤‡å®Œæˆ')

    // 2. å½’æ¡£ææ–™æµæ°´
    const materialWhereClause = beforeDate ? `WHERE created_at < '${beforeDate}'` : ''
    const [materialResult] = await sequelize.query(
      `
      INSERT INTO material_transactions_history
      SELECT * FROM material_transactions
      ${materialWhereClause}
      LIMIT ${batchSize}
    `,
      { transaction }
    )

    const materialArchived = materialResult.affectedRows || 0
    logger.info(`ææ–™æµæ°´å½’æ¡£å®Œæˆ`, { archived: materialArchived })

    // 3. å½’æ¡£é’»çŸ³æµæ°´
    const diamondWhereClause = beforeDate ? `WHERE created_at < '${beforeDate}'` : ''
    const [diamondResult] = await sequelize.query(
      `
      INSERT INTO diamond_transactions_history
      SELECT * FROM diamond_transactions
      ${diamondWhereClause}
      LIMIT ${batchSize}
    `,
      { transaction }
    )

    const diamondArchived = diamondResult.affectedRows || 0
    logger.info(`é’»çŸ³æµæ°´å½’æ¡£å®Œæˆ`, { archived: diamondArchived })

    // 4. åˆ é™¤å·²å½’æ¡£çš„æ•°æ®ï¼ˆå¯é€‰ï¼Œæ ¹æ®ä¸šåŠ¡éœ€æ±‚å†³å®šï¼‰
    // æ³¨æ„ï¼šç”±äºè¡¨å·²è®¾ç½®ä¸ºåªè¯»ï¼Œæ­¤æ­¥éª¤ä¼šå¤±è´¥ï¼Œéœ€è¦åœ¨å½’æ¡£å‰ä¸´æ—¶æˆäºˆæƒé™
    // await sequelize.query(`
    //   DELETE FROM material_transactions ${materialWhereClause} LIMIT ${batchSize}
    // `, { transaction })
    // await sequelize.query(`
    //   DELETE FROM diamond_transactions ${diamondWhereClause} LIMIT ${batchSize}
    // `, { transaction })

    await transaction.commit()

    return {
      material_archived: materialArchived,
      diamond_archived: diamondArchived
    }
  } catch (error) {
    await transaction.rollback()
    throw error
  }
}

// å¯¼å‡ºåˆ°æ–‡ä»¶
async function exportToFile(beforeDate, outputPath, batchSize) {
  logger.info('å¼€å§‹å¯¼å‡ºåˆ°æ–‡ä»¶...', { beforeDate, outputPath, batchSize })

  // æ„å»ºæŸ¥è¯¢æ¡ä»¶
  const materialWhereClause = beforeDate ? `WHERE created_at < '${beforeDate}'` : ''
  const diamondWhereClause = beforeDate ? `WHERE created_at < '${beforeDate}'` : ''

  // æŸ¥è¯¢ææ–™æµæ°´
  const materialTransactions = await sequelize.query(
    `
    SELECT * FROM material_transactions
    ${materialWhereClause}
    ORDER BY created_at ASC
    LIMIT ${batchSize}
  `,
    {
      type: sequelize.QueryTypes.SELECT
    }
  )

  // æŸ¥è¯¢é’»çŸ³æµæ°´
  const diamondTransactions = await sequelize.query(
    `
    SELECT * FROM diamond_transactions
    ${diamondWhereClause}
    ORDER BY created_at ASC
    LIMIT ${batchSize}
  `,
    {
      type: sequelize.QueryTypes.SELECT
    }
  )

  // æ„å»ºå¯¼å‡ºæ•°æ®
  const exportData = {
    export_info: {
      exported_at: formatTime(new Date()),
      before_date: beforeDate || 'å…¨éƒ¨æ•°æ®',
      batch_size: batchSize,
      total_material_transactions: materialTransactions.length,
      total_diamond_transactions: diamondTransactions.length
    },
    material_transactions: materialTransactions,
    diamond_transactions: diamondTransactions
  }

  // ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
  const outputDir = path.dirname(outputPath)
  await fs.mkdir(outputDir, { recursive: true })

  // å†™å…¥æ–‡ä»¶
  await fs.writeFile(outputPath, JSON.stringify(exportData, null, 2), 'utf8')

  logger.info('å¯¼å‡ºåˆ°æ–‡ä»¶å®Œæˆ', {
    outputPath,
    material_count: materialTransactions.length,
    diamond_count: diamondTransactions.length
  })

  return {
    material_exported: materialTransactions.length,
    diamond_exported: diamondTransactions.length,
    output_path: outputPath
  }
}

// ä¸»å‡½æ•°
async function main() {
  try {
    const options = parseArgs()

    logger.info('========================================')
    logger.info('æ—§ææ–™å’Œé’»çŸ³æµæ°´å½’æ¡£è„šæœ¬ï¼ˆPhase 4ï¼‰')
    logger.info('========================================')
    logger.info('æ‰§è¡Œå‚æ•°:', options)

    // éªŒè¯å‚æ•°
    validateOptions(options)

    // 1. ç»Ÿè®¡æ•°æ®
    logger.info('æ­£åœ¨ç»Ÿè®¡æ—§æµæ°´æ•°æ®...')
    const stats = await statisticsLegacyTransactions(options.beforeDate)

    logger.info('========================================')
    logger.info('æ—§æµæ°´æ•°æ®ç»Ÿè®¡ç»“æœ:')
    logger.info('========================================')
    logger.info(`ğŸ“Š ææ–™æµæ°´æ€»æ•°: ${stats.material_transactions}`)
    if (stats.earliest_material) {
      logger.info(`   æœ€æ—©è®°å½•: ${formatTime(stats.earliest_material)}`)
      logger.info(`   æœ€æ™šè®°å½•: ${formatTime(stats.latest_material)}`)
    }
    logger.info(`ğŸ“Š é’»çŸ³æµæ°´æ€»æ•°: ${stats.diamond_transactions}`)
    if (stats.earliest_diamond) {
      logger.info(`   æœ€æ—©è®°å½•: ${formatTime(stats.earliest_diamond)}`)
      logger.info(`   æœ€æ™šè®°å½•: ${formatTime(stats.latest_diamond)}`)
    }
    logger.info('========================================')

    // 2. å¦‚æœæ˜¯dry-runï¼Œåˆ™åªç»Ÿè®¡ä¸æ‰§è¡Œ
    if (options.dryRun) {
      logger.info('âœ… Dry-run æ¨¡å¼ï¼Œä»…ç»Ÿè®¡æ•°æ®ï¼Œä¸æ‰§è¡Œå½’æ¡£æ“ä½œ')
      process.exit(0)
    }

    // 3. æ‰§è¡Œå½’æ¡£æˆ–å¯¼å‡º
    if (stats.material_transactions === 0 && stats.diamond_transactions === 0) {
      logger.info('âš ï¸ æ²¡æœ‰éœ€è¦å½’æ¡£çš„æ•°æ®')
      process.exit(0)
    }

    let result
    if (options.mode === 'archive') {
      logger.info('âš ï¸ æ³¨æ„: å½’æ¡£åˆ°å†å²è¡¨æ¨¡å¼éœ€è¦æ•°æ®åº“å†™æƒé™')
      logger.info('âš ï¸ ç”±äºæ—§è¡¨å·²è®¾ç½®ä¸ºåªè¯»ï¼Œæ­¤æ“ä½œå¯èƒ½å¤±è´¥')
      logger.info('âš ï¸ è¯·ç¡®ä¿åœ¨æ‰§è¡Œå½’æ¡£å‰ä¸´æ—¶æˆäºˆå†™æƒé™æˆ–ä½¿ç”¨ export æ¨¡å¼')
      result = await archiveToHistoryTables(options.beforeDate, options.batchSize)

      logger.info('========================================')
      logger.info('å½’æ¡£åˆ°å†å²è¡¨å®Œæˆ:')
      logger.info(`âœ… ææ–™æµæ°´å½’æ¡£: ${result.material_archived} æ¡`)
      logger.info(`âœ… é’»çŸ³æµæ°´å½’æ¡£: ${result.diamond_archived} æ¡`)
      logger.info('========================================')
    } else if (options.mode === 'export') {
      result = await exportToFile(options.beforeDate, options.output, options.batchSize)

      logger.info('========================================')
      logger.info('å¯¼å‡ºåˆ°æ–‡ä»¶å®Œæˆ:')
      logger.info(`âœ… ææ–™æµæ°´å¯¼å‡º: ${result.material_exported} æ¡`)
      logger.info(`âœ… é’»çŸ³æµæ°´å¯¼å‡º: ${result.diamond_exported} æ¡`)
      logger.info(`âœ… è¾“å‡ºæ–‡ä»¶: ${result.output_path}`)
      logger.info('========================================')
    }

    logger.info('âœ… å†å²æµæ°´å½’æ¡£ä»»åŠ¡å®Œæˆ')
    process.exit(0)
  } catch (error) {
    logger.error('âŒ å½’æ¡£è„šæœ¬æ‰§è¡Œå¤±è´¥', {
      error: error.message,
      stack: error.stack
    })
    process.exit(1)
  } finally {
    await sequelize.close()
  }
}

// æ‰§è¡Œä¸»å‡½æ•°
if (require.main === module) {
  main()
}

module.exports = { statisticsLegacyTransactions, archiveToHistoryTables, exportToFile }
