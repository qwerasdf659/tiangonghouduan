---
description: 
globs: 
alwaysApply: true
---
# 文档生成和缓存管理规范（基于实际冗余问题优化版 v2.0）

## 🔴 基于cursor_1.md超标案例的紧急优化（2025年01月12日）

### 严重文档膨胀实际案例分析

#### cursor_1.md超标问题统计
- **实际大小**: 213KB, 7258行（史上最严重膨胀案例）
- **任务性质**: 后端服务状态检查（应该是简单任务）
- **应该大小**: 2KB, 50行以内
- **超标比例**: 10650%（106倍超标）
- **信息重复率**: 300-500%（极其严重）

#### 具体膨胀内容分析
```markdown
# cursor_1.md中发现的重复内容模式：

## 健康检查记录重复8次
✅ 服务：运行中（进程40469）
✅ 端口：3000正常监听  
✅ 数据库：连接正常
✅ 健康检查：正常响应
# ... 以上内容在文档中重复了8次！

## 相同的curl命令输出重复记录
curl http://localhost:3000/health
{"status":"healthy","timestamp":"..."}
# ... 相同的输出被记录了8次！

## 重复的验证确认
**任务完成** - 后端服务完全正常运行。
# ... 类似的确认重复出现15+次！
```

#### 信息密度计算
```javascript
// cursor_1.md信息密度分析
const docAnalysis = {
  totalLines: 7258,
  uniqueInformation: 50,      // 实际有用信息只有50行
  redundantRate: 99.3,        // 99.3%都是冗余信息
  repeatCount: {
    healthCheck: 8,           // 健康检查重复8次
    statusConfirm: 15,        // 状态确认重复15次
    commandOutput: 12,        // 命令输出重复12次
    taskComplete: 18          // 任务完成重复18次
  }
};

// 信息密度 = 有用信息 / 总信息 = 50 / 7258 = 0.7%
console.log(`信息密度：${(docAnalysis.uniqueInformation / docAnalysis.totalLines * 100).toFixed(1)}%`);
```

### 文档长度硬性限制和超标处罚

#### 按任务复杂度强制控制（基于实际案例）
```javascript
// 基于cursor_1.md案例制定的硬性限制
const DOC_LENGTH_CONTROLS = {
  status_check: {
    maxLines: 50,           // cursor_1.md应该控制在50行内
    maxSize: '2KB',         // 而不是213KB
    penalty: 'SEVERE',      // 超标处罚级别
    template: 'status_simple.md'
  },
  
  simple_debug: {
    maxLines: 100,
    maxSize: '5KB',
    penalty: 'MODERATE',
    template: 'debug_simple.md'
  },
  
  medium_task: {
    maxLines: 200,
    maxSize: '10KB', 
    penalty: 'WARNING',
    template: 'task_medium.md'
  },
  
  complex_task: {
    maxLines: 500,          // 绝对上限
    maxSize: '25KB',        // 绝对上限
    penalty: 'CRITICAL',
    template: 'task_complex.md'
  }
};

// 文档长度验证和自动截断
function validateAndTruncateDoc(content, taskType) {
  const lines = content.split('\n');
  const limit = DOC_LENGTH_CONTROLS[taskType];
  
  if (lines.length > limit.maxLines) {
    console.error(`🚫 文档超长：${lines.length}行 > ${limit.maxLines}行限制`);
    
    // 自动截断到限制长度
    const truncated = lines.slice(0, limit.maxLines);
    truncated.push('', '--- 文档已截断，超出长度限制 ---');
    
    return {
      content: truncated.join('\n'),
      truncated: true,
      originalLength: lines.length,
      newLength: limit.maxLines
    };
  }
  
  return { content, truncated: false };
}
```

### 重复内容智能检测和清理

#### 基于cursor_1.md的重复模式检测算法
```javascript
// 重复内容检测算法（基于实际发现的模式）
function detectRepeatPatterns(content) {
  const lines = content.split('\n');
  const patterns = {
    healthCheck: /curl.*localhost:3000\/health/,
    statusConfirm: /✅.*服务.*运行中/,
    taskComplete: /任务完成.*后端服务.*正常/,
    commandOutput: /\{"status":"healthy"/
  };
  
  const detectedRepeats = {};
  
  Object.keys(patterns).forEach(patternName => {
    const matches = lines.filter(line => patterns[patternName].test(line));
    if (matches.length > 1) {
      detectedRepeats[patternName] = {
        count: matches.length,
        firstLine: lines.indexOf(matches[0]) + 1,
        lines: matches
      };
    }
  });
  
  return detectedRepeats;
}

// 自动去重算法
function autoDeduplication(content) {
  const repeats = detectRepeatPatterns(content);
  let cleanedContent = content;
  
  Object.keys(repeats).forEach(patternName => {
    const pattern = repeats[patternName];
    if (pattern.count > 2) {
      console.log(`🧹 清理重复内容：${patternName} (${pattern.count}次 -> 1次)`);
      
      // 保留第一个，删除其余
      const firstLine = pattern.lines[0];
      const regex = new RegExp(escapeRegExp(firstLine), 'g');
      let matchCount = 0;
      
      cleanedContent = cleanedContent.replace(regex, (match) => {
        matchCount++;
        return matchCount === 1 ? match : ''; // 只保留第一个匹配
      });
    }
  });
  
  return cleanedContent;
}
```

### 信息密度强制要求（解决0.7%密度问题）

#### 信息密度量化标准
```javascript
// 基于cursor_1.md的负面案例制定标准
const INFO_DENSITY_STANDARDS = {
  minimum_density: 0.4,      // 最低40%信息密度
  target_density: 0.7,       // 目标70%信息密度
  excellent_density: 0.9,    // 优秀90%信息密度
  
  // cursor_1.md实际密度: 0.007 (0.7%) - 严重不合格
  failure_threshold: 0.1     // 低于10%视为严重失败
};

function calculateInfoDensity(content) {
  const lines = content.split('\n').filter(line => line.trim());
  const meaningfulLines = lines.filter(line => {
    // 排除空行、重复行、装饰行
    return !isDecorative(line) && 
           !isRepeat(line) && 
           hasMeaningfulContent(line);
  });
  
  const density = meaningfulLines.length / lines.length;
  
  if (density < INFO_DENSITY_STANDARDS.failure_threshold) {
    throw new Error(`🚫 信息密度严重不足：${(density*100).toFixed(1)}% < ${(INFO_DENSITY_STANDARDS.failure_threshold*100)}%`);
  }
  
  return density;
}

function hasMeaningfulContent(line) {
  const meaninglessPatterns = [
    /^#{1,6}\s*$/,                    // 空标题
    /^-{3,}$/,                        // 分割线
    /^✅.*正常.*$/,                   // 重复的状态确认
    /^.*任务完成.*$/,                 // 重复的完成确认
    /^\s*```\s*$/,                    // 空代码块
    /^.*已完成.*$/                    // 重复的完成标记
  ];
  
  return !meaninglessPatterns.some(pattern => pattern.test(line));
}
```

### 标准文档模板强制使用（防止cursor_1.md式膨胀）

#### 状态检查标准模板（最大50行）
```markdown
# 后端服务状态检查

## 检查结果（5秒并行检查）
✅ 服务状态：运行中 (PID: 40469)
✅ 端口监听：3000端口正常
✅ 数据库连接：healthy
✅ 健康检查：正常响应

## 核心数据
- 用户：33个 | 奖品：8个 | 商品：11个
- 内存：76MB | 响应时间：30ms

## 总结
后端服务完全正常，无需任何修复。

**任务完成**
```

#### 模板强制验证
```javascript
// 强制使用模板验证
function enforceTemplate(content, taskType) {
  const templates = {
    status_check: {
      requiredSections: ['检查结果', '总结'],
      maxSections: 4,
      forbiddenPatterns: [
        /重复.*检查/,           // 禁止重复检查描述
        /.*已完成.*已完成/,     // 禁止重复完成确认
        /curl.*curl/           // 禁止重复命令记录
      ]
    }
  };
  
  const template = templates[taskType];
  if (!template) return true;
  
  // 检查禁止模式
  template.forbiddenPatterns.forEach(pattern => {
    if (pattern.test(content)) {
      throw new Error(`🚫 检测到禁止模式：${pattern.source}`);
    }
  });
  
  return true;
}
```

### 实时文档质量监控

#### 文档质量评分系统
```javascript
function calculateDocQuality(content, taskType) {
  const metrics = {
    length: calculateLengthScore(content, taskType),
    density: calculateInfoDensity(content),
    repetition: calculateRepetitionScore(content),
    structure: calculateStructureScore(content)
  };
  
  const weights = {
    length: 0.3,      // 长度控制30%
    density: 0.4,     // 信息密度40%
    repetition: 0.2,  // 重复控制20%
    structure: 0.1    // 结构质量10%
  };
  
  const totalScore = Object.keys(metrics).reduce((sum, key) => {
    return sum + metrics[key] * weights[key];
  }, 0);
  
  return {
    score: totalScore,
    grade: getGrade(totalScore),
    metrics: metrics,
    suggestions: generateSuggestions(metrics)
  };
}

function getGrade(score) {
  if (score >= 0.9) return 'A';
  if (score >= 0.8) return 'B';  
  if (score >= 0.7) return 'C';
  if (score >= 0.6) return 'D';
  return 'F'; // cursor_1.md级别的失败
}
```

## 严重文档冗余问题分析

### 实际文档膨胀统计
基于实际文档分析：
- **cursor_1.md**：213KB，7258行（严重膨胀）
- **cursor_5.md**：38KB，1375行（中度膨胀）  
- **cursor_.md**：91KB，2956行（中度膨胀）
- **信息重复率**：300-500%（极其严重）

### 文档长度控制强制规范

#### 按问题复杂度严格控制
```javascript
// 文档长度控制算法
const DOC_LIMITS = {
  simple: {
    maxLines: 50,        // 配置修复、状态检查等
    maxSize: '2KB',
    examples: ['API路径修复', '服务重启', '配置调整']
  },
  medium: {
    maxLines: 200,       // 代码逻辑修复、功能调试等  
    maxSize: '8KB',
    examples: ['接口调试', '权限修复', '数据库问题']
  },
  complex: {
    maxLines: 500,       // 系统重构、架构调整等
    maxSize: '20KB', 
    examples: ['系统升级', '架构重构', '大型功能开发']
  }
}

// 超出限制自动截断
if (docLines > DOC_LIMITS[complexity].maxLines) {
  throw new Error(`文档超出${complexity}问题限制：${docLines}行 > ${DOC_LIMITS[complexity].maxLines}行`);
}
```

#### 实际超标案例分析
**cursor_1.md问题分析**：
- 实际内容：后端服务启动检查
- 问题复杂度：简单（应该50行）
- 实际长度：7258行（超标14416%）
- 主要冗余：重复的状态检查记录

**优化后应该的格式**：
```markdown
# 后端服务启动

## 状态检查
✅ 服务：运行中（进程40469）
✅ 端口：3000正常监听  
✅ 数据库：连接正常
✅ 健康检查：正常响应

## 解决方案
无需修复，所有服务正常。

## 验证结果
curl http://localhost:3000/health → {"status":"healthy"}

**任务完成** - 后端服务完全正常运行。
```

### 信息重复检测和清理

#### 实际重复信息模式
发现的重复模式：
1. **状态检查结果重复**：健康检查结果记录8次
2. **命令执行重复**：相同命令重复记录6-7次
3. **分析过程重复**：相同的思考过程重复描述
4. **验证结果重复**：相同的验证结果重复确认

#### 重复信息自动清理算法
```javascript
// 重复内容检测
function detectDuplicates(content) {
  const blocks = content.split('\n\n');
  const duplicates = [];
  
  for (let i = 0; i < blocks.length; i++) {
    for (let j = i + 1; j < blocks.length; j++) {
      const similarity = calculateSimilarity(blocks[i], blocks[j]);
      if (similarity > 0.8) {  // 80%相似度阈值
        duplicates.push({ index: j, similarity, original: i });
      }
    }
  }
  
  return duplicates;
}

// 自动删除重复内容
function removeDuplicates(content) {
  const duplicates = detectDuplicates(content);
  const blocks = content.split('\n\n');
  
  // 从后往前删除，避免索引变化
  duplicates.sort((a, b) => b.index - a.index);
  duplicates.forEach(dup => {
    blocks.splice(dup.index, 1);
    console.log(`删除重复内容（相似度${dup.similarity}）`);
  });
  
  return blocks.join('\n\n');
}
```

### 工具调用效率优化（详细规则见02-tool-optimization-standards.mdc）

#### 效率优化核心指标
- **目标工具调用数**：简单任务<20次，中等任务<50次，复杂任务<100次
- **cursor_1.md教训**：180+次调用严重超标，主要浪费在重复状态检查
- **优化重点**：重复检测、并行化、结果缓存

> 详细的工具调用预算算法、重复检测机制和并行化策略请参考 `02-tool-optimization-standards.mdc`

### 缓存管理效率优化

#### 实际缓存问题分析
发现的缓存问题：
- **文件状态缓存**：list_dir显示与实际不符3次
- **服务状态缓存**：健康检查结果未缓存，重复检查8次
- **API响应缓存**：相同请求重复执行5次

#### 智能缓存策略
```javascript
// 分层缓存策略
const cacheStrategy = {
  // 1分钟缓存：快速变化的状态
  short: {
    ttl: 60000,
    items: ['process_status', 'port_status', 'memory_usage']
  },
  
  // 5分钟缓存：相对稳定的状态  
  medium: {
    ttl: 300000,
    items: ['health_check', 'service_status', 'database_connection']
  },
  
  // 30分钟缓存：基本不变的信息
  long: {
    ttl: 1800000,
    items: ['project_structure', 'config_files', 'dependencies']
  }
}

// 缓存失效策略
function invalidateCache(operation) {
  const invalidationRules = {
    'file_edit': ['file_content', 'project_structure'],
    'service_restart': ['health_check', 'process_status', 'port_status'],
    'config_change': ['config_files', 'service_status']
  };
  
  const toInvalidate = invalidationRules[operation] || [];
  toInvalidate.forEach(cacheKey => {
    delete cache[cacheKey];
    console.log(`缓存失效：${cacheKey}`);
  });
}
```

# 文档生成和缓存管理规范
# 解决文档冗余、信息过载和工具调用效率问题

## 核心问题分析
通过对实际会话的深度分析，发现以下严重的文档和缓存管理问题：
- 文档冗余度：300-500%的信息重复
- 简单问题复杂化：50行问题生成1000+行文档
- 重点信息掩盖：关键信息被大量细节掩盖
- 工具调用浪费：重复工具调用次数30-40次
- 缓存利用率低：重复状态检查浪费大量请求

## 文档长度控制规范

### 按问题复杂度分级控制
- **简单问题（查询、配置）**：
  - 文档长度：30-50行
  - 核心信息占比：>80%
  - 阅读时间：<2分钟

- **中等问题（调试、修复）**：
  - 文档长度：100-200行
  - 核心信息占比：>60%
  - 阅读时间：<5分钟

- **复杂问题（系统性改造）**：
  - 文档长度：300-500行
  - 核心信息占比：>40%
  - 阅读时间：<10分钟

### 文档结构强制要求
- **执行摘要**（必须）：3-5行概述
- **问题描述**（必须）：简洁描述问题现象
- **解决方案**（必须）：具体操作步骤
- **验证结果**（必须）：修复效果确认
- **技术细节**（可选）：详细技术信息，可折叠
- **相关信息**（可选）：补充信息，可删减

### 信息密度要求
- **信息密度**：每行至少包含1个有效信息点
- **冗余率控制**：重复信息不超过10%
- **空白率控制**：空白行不超过20%
- **有效信息率**：核心信息占比>50%

## 内容精简策略

### 信息重要性分级
- **P0级（必须保留）**：解决问题必需的信息
- **P1级（高度相关）**：有助于理解和操作的信息
- **P2级（一般相关）**：提供背景和扩展的信息
- **P3级（低度相关）**：可有可无的补充信息

### 内容删减原则
- **删除重复**：合并相同或相似的信息
- **删除冗余**：删除不影响理解的重复表述
- **删除无关**：删除与解决问题无关的信息
- **删除过程**：简化详细的操作过程描述

### 信息压缩技术
- **列表化**：将长段落转换为简洁列表
- **表格化**：使用表格整理结构化信息
- **代码块**：将操作步骤整理为代码块
- **关键词提取**：提取关键信息点

## 结构化文档模板

### 问题解决文档模板
```markdown
# 问题：[一句话描述]

## 解决方案
[核心解决步骤，3-5步]

## 验证结果
[验证效果的具体方法]

## 预防建议
[防止再次发生的建议]

---
<details>
<summary>技术细节（点击展开）</summary>
[详细的技术分析和背景信息]
</details>
```

### 配置修改文档模板
```markdown
# 配置：[配置项名称]

## 修改内容
- 文件：`path/to/file`
- 原值：`old_value`
- 新值：`new_value`

## 生效方法
[使配置生效的操作]

## 验证方法
[验证配置是否生效]
```

### 功能实现文档模板
```markdown
# 功能：[功能名称]

## 实现概述
[功能实现的核心逻辑]

## 关键代码
```language
[核心代码片段]
```

## 测试验证
[功能测试的方法和结果]
```

## 信息呈现优化

### 视觉层次优化
- **标题层次**：最多使用3级标题
- **重点标记**：使用粗体标记关键信息
- **代码突出**：使用代码块突出命令和配置
- **列表简化**：使用简洁的列表格式

### 阅读顺序优化
- **重要信息前置**：将最重要的信息放在前面
- **操作步骤序号**：为操作步骤添加清晰序号
- **结果验证分离**：将验证步骤单独成段
- **补充信息后置**：将详细信息放在文档后部

### 信息分层展示
- **核心信息**：直接显示在主文档中
- **详细信息**：使用折叠区域隐藏
- **技术细节**：使用详情标签包装
- **历史信息**：移至文档末尾或删除

## 重复信息检测

### 自动检测机制
- **文本相似度检测**：检测相似度>70%的文本块
- **关键词频率分析**：分析关键词出现频率
- **段落重复检测**：检测完全重复的段落
- **结构重复识别**：识别相似的文档结构

### 重复信息处理策略
- **合并处理**：将重复信息合并为一处
- **引用处理**：使用引用替代重复描述
- **删除处理**：直接删除冗余的重复信息
- **链接处理**：使用内部链接减少重复

### 信息去重算法
```
去重流程：
1. 识别候选重复块
2. 计算文本相似度
3. 分析信息价值
4. 选择保留版本
5. 处理其他重复版本
6. 更新文档索引
```

## 工具调用效率优化规范

### 工具调用次数控制规范
- **严禁重复工具调用**：同一会话中避免对相同内容进行重复的状态检查、文件读取、命令执行
- **关键系统状态检查结果应缓存使用**：避免在同一会话中重复验证
- **工具调用前评估必要性**：确保不是重复或冗余操作
- **限制验证频率**：同类验证操作在单个会话中不超过2次，除非确实需要验证变更结果

### 状态检查去重机制
- **建立检查清单**：会话开始时建立已完成检查项目清单，避免重复验证
- **状态变更触发**：仅在相关操作完成后重新检查状态，而非每次操作前都检查
- **集中状态验证**：将多个相关状态检查集中在一次工具调用中完成
- **避免冗余确认**：对已确认正常的服务状态，除非有错误发生否则不重复检查

### 工具调用效率监控
- **效率指标跟踪**：跟踪工具调用成功率、重复率、并行化率等关键指标
- **失败分析机制**：工具调用失败时立即分析原因，制定针对性的替代方案
- **时间效率要求**：单次工具调用操作时间不超过30秒，长操作必须分段或后台执行
- **请求次数预算**：为每类任务设定合理的工具调用次数预算，超出时进行优化

## 并行工具调用最大化规范

### 并行处理强制要求
- **系统状态检查并行化**：端口占用、进程状态、健康检查等独立检查必须并行执行
- **文件操作并行化**：存在性检查与内容读取、多个配置文件读取可以并行进行
- **网络请求并行化**：多个API端点测试、多个服务健康检查必须并行执行
- **数据库操作并行化**：不相关的数据库查询可以并行执行
- **信息收集并行化**：所有独立的信息收集任务必须并行执行

### 并行处理执行规范
- **默认并行原则**：除非有明确的依赖关系，否则所有工具调用都应并行执行
- **串行限制条件**：只有当工具B的输入确实需要工具A的输出时，才能串行执行
- **并行调用限制**：同时执行的并行工具调用建议不超过5个，避免系统资源耗尽
- **错误处理并行**：并行工具调用中的错误处理不应影响其他并行任务的执行

### 并行效率优化策略
- **批量操作优化**：多个独立的检查操作必须使用并行工具调用，避免串行等待
- **预分析策略**：在工具调用前分析所有需要的信息，一次性并行获取
- **避免假并行**：确保声称的并行操作确实是真正的并行，而不是顺序包装
- **并行化率目标**：独立操作的并行化率应达到80%以上

## 智能重试策略规范

### 重试逻辑优化
- **智能重试机制**：工具调用失败时分析失败原因，避免盲目重试浪费请求次数
- **重试次数限制**：同类操作重试不超过2次，不同方法重试不超过3次
- **替代方案机制**：重试失败时立即切换到替代方案，而非无限重试
- **错误类型分类**：根据错误类型选择重试策略或直接切换方案

### 故障转移机制
- **工具切换策略**：主工具失败时立即切换到备用工具（如file_search → grep_search）
- **方法降级策略**：复杂操作失败时降级到简单操作（如并行 → 串行）
- **用户提示机制**：无法自动恢复时及时提示用户介入

## 缓存管理规范

### 缓存策略分类
- **会话级缓存**：项目信息、技术栈、配置文件内容
- **操作级缓存**：状态检查结果、系统信息、网络连接状态
- **临时缓存**：命令执行结果、文件读取内容
- **长期缓存**：项目结构、依赖关系、环境配置

### 缓存有效期管理
- **静态信息缓存**：整个会话期间有效
- **动态信息缓存**：5-10分钟有效期
- **状态信息缓存**：操作前后失效
- **文件内容缓存**：文件修改后失效

### 缓存失效策略
- **主动失效**：关键操作后主动清除相关缓存
- **时间失效**：到达有效期后自动失效
- **依赖失效**：依赖项变更后连带失效
- **手动失效**：用户要求或检测到不一致时失效

## 用户体验优化

### 阅读体验提升
- **扫描友好**：支持快速扫描查找信息
- **跳跃阅读**：支持跳跃式阅读关键信息
- **渐进披露**：按需展示详细信息
- **快速定位**：提供快速定位机制

### 操作便利性
- **复制友好**：命令和代码易于复制
- **执行顺序**：操作步骤按执行顺序排列
- **错误处理**：包含常见错误的处理方法
- **回滚指导**：提供操作回滚的指导

### 理解辅助
- **上下文提供**：提供必要的背景信息
- **术语解释**：解释关键技术术语
- **示例说明**：使用具体示例说明抽象概念
- **图示补充**：必要时使用图示辅助理解

## 效率测量和优化指标

### 关键效率指标
- **工具调用效率**：成功率 >90%，重复率 <10%，并行化率 >80%
- **会话完成时间**：问题定位时间 <5分钟，总解决时间目标
- **成本控制指标**：单次会话工具调用次数控制在合理范围内
- **文档质量指标**：完整性、准确性、简洁性、可操作性

### 持续优化机制
- **效率分析记录**：记录工具调用模式和效率指标
- **问题模式识别**：识别重复出现的低效模式
- **优化策略更新**：定期更新优化策略和最佳实践
- **知识库建设**：建立高效工具调用的知识库和模板

## 质量控制机制

### 文档质量指标
- **完整性**：包含解决问题的完整信息
- **准确性**：信息的准确性和时效性
- **简洁性**：信息表达的简洁性
- **可操作性**：操作指导的可执行性

### 质量检查清单
- [ ] 核心问题是否清晰描述？
- [ ] 解决方案是否具体可行？
- [ ] 验证方法是否明确有效？
- [ ] 文档长度是否合理控制？
- [ ] 重复信息是否已经清理？
- [ ] 用户是否能够快速理解？

### 文档评审机制
- **自我评审**：作者自我检查文档质量
- **同行评审**：其他专家评审文档内容
- **用户反馈**：收集用户对文档的反馈
- **迭代改进**：基于反馈持续改进文档质量

## 文档生成自动化

### 模板自动化
- **模板识别**：自动识别适用的文档模板
- **内容填充**：自动填充模板的固定内容
- **格式标准化**：自动应用标准格式和样式
- **结构优化**：自动优化文档结构和层次

### 内容生成优化
- **信息提取**：从原始数据中提取关键信息
- **内容组织**：按重要性和逻辑顺序组织内容
- **语言优化**：使用简洁明了的语言表达
- **格式统一**：统一文档格式和风格

### 质量保证自动化
- **重复检测**：自动检测和标记重复内容
- **完整性检查**：自动检查文档完整性
- **准确性验证**：自动验证关键信息的准确性
- **可读性分析**：自动分析文档可读性

## 缓存一致性保证

### 一致性检测
- **版本控制**：为缓存数据建立版本控制
- **完整性检查**：定期检查缓存数据完整性
- **时效性验证**：验证缓存数据的时效性
- **依赖关系验证**：验证缓存数据间的依赖关系

### 不一致处理
- **冲突检测**：检测缓存数据的冲突
- **冲突解决**：制定冲突解决策略
- **数据修复**：修复不一致的缓存数据
- **预防措施**：制定预防不一致的措施

### 同步机制
- **实时同步**：关键数据的实时同步
- **批量同步**：非关键数据的批量同步
- **异步同步**：长时间操作的异步同步
- **优先级同步**：按优先级进行同步

## 实施检查清单

### 每次会话开始前
- [ ] 明确会话目标和所需信息
- [ ] 分析哪些操作可以并行执行
- [ ] 建立已完成检查项目清单
- [ ] 设定工具调用次数预算

### 每次工具调用前
- [ ] 检查是否为重复调用
- [ ] 评估是否可以并行执行
- [ ] 确认调用的必要性
- [ ] 预估调用时间和成本

### 每次文档生成时
- [ ] 确认文档长度合理
- [ ] 检查信息密度符合要求
- [ ] 验证内容结构标准化
- [ ] 删除重复和冗余信息

### 每次会话结束后
- [ ] 统计工具调用次数和效率
- [ ] 分析是否存在重复或冗余调用
- [ ] 识别可以并行化的操作
- [ ] 记录优化建议和改进点

## 技术实现建议

### 缓存存储结构
```json
{
  "session_id": "unique_session_id",
  "cache_data": {
    "project_info": {
      "type": "nodejs_backend",
      "framework": "express",
      "timestamp": "2024-01-01T00:00:00Z",
      "ttl": 3600
    },
    "system_status": {
      "services": ["mysql", "redis", "nginx"],
      "timestamp": "2024-01-01T00:00:00Z",
      "ttl": 300
    }
  }
}
```

### 工具调用优化算法
```python
def optimize_tool_calls(operations):
    # 分析操作依赖关系
    dependencies = analyze_dependencies(operations)
    
    # 识别可并行操作
    parallel_groups = identify_parallel_groups(operations, dependencies)
    
    # 优化执行顺序
    optimized_plan = optimize_execution_order(parallel_groups)
    
    return optimized_plan
```

### 文档生成工作流
```
1. 收集原始信息
2. 分析信息重要性
3. 选择合适模板
4. 生成初始文档
5. 检测重复内容
6. 精简和优化
7. 格式化输出
8. 质量检查
```

**核心原则**：效率优先、避免重复、并行最大化、成本控制、质量保证、用户体验
